# Polynomial Regression & Model Complexity Analysis
### A Biasâ€“Variance and Regularization Case Study

## ğŸ“Œ Project Objective

This project investigates model complexity using Polynomial Regression 
on the Energy Efficiency dataset.

The goal is to:

- Study the Biasâ€“Variance tradeoff
- Analyze overfitting in high-degree polynomial models
- Evaluate the impact of Ridge regularization
- Compare model performance across different complexity levels

---

## ğŸ“Š Dataset

Energy Efficiency Dataset (768 samples, 8 features)

Target variable:
- Heating Load

The dataset describes building characteristics and their energy efficiency performance.

---

## ğŸ§  Methodology

### 1ï¸âƒ£ Baseline Model
- Linear Regression
- Train/Test split (80/20)
- RMSE and RÂ² evaluation

### 2ï¸âƒ£ Polynomial Regression
- Degrees tested: 1 â†’ 6
- Train vs Test error comparison
- Model complexity curve visualization

### 3ï¸âƒ£ Regularization
- Ridge Regression applied to degree 6
- Multiple alpha values tested
- Generalization improvement analysis

---

## ğŸ“ˆ Results

### Linear Regression
- Test RMSE â‰ˆ 3.02
- Test RÂ² â‰ˆ 0.91

### Best Polynomial Model
- Degree 4
- Test RMSE â‰ˆ 0.45
- Test RÂ² â‰ˆ 0.998

### Overfitting Example
Degree 6 without regularization:
- Train RMSE â‰ˆ 0.14
- Test RMSE â‰ˆ 0.96

### Regularization Effect
Degree 6 + Ridge (alpha = 0.001):
- Test RMSE reduced to â‰ˆ 0.48

---

## ğŸ” Key Insights

- Increasing polynomial degree reduces bias but increases variance.
- Model performance improves up to degree 4.
- Higher degrees cause overfitting.
- Ridge regularization successfully stabilizes high-complexity models.
- Regularization shrinks coefficients and improves generalization.

